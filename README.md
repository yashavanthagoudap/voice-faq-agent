# ğŸ§ AI-Powered Voice FAQ Agent (Python Backend)

## ğŸ“Œ Overview

This project implements an **AI-powered voice-based customer support agent** that answers user questions **strictly from a provided FAQ PDF**.

The agent accepts **live microphone input**, converts speech to text, retrieves the most relevant answer from the FAQ document, converts the response back to speech, and maintains a **full conversation transcript**.

If a user asks a question **outside the scope of the FAQ**, or if the speech input is **unclear**, the agent gracefully handles the situation by **requesting clarification** or **transferring the call to a live agent**, exactly as required by the assignment.

---

## âœ¨ Key Features

* ğŸ™ï¸ Live voice interaction using microphone input (Streamlit)
* ğŸ—£ï¸ Speech-to-Text (STT) using **Vosk** (fully open-source, offline)
* ğŸ” FAQ-based question answering (PDF-only)
* ğŸ§  Semantic retrieval using sentence embeddings + FAISS
* ğŸ”Š Text-to-Speech (TTS) for spoken responses
* ğŸš« Strict non-hallucination policy
* ğŸ¤ Graceful clarification for unclear speech
* ğŸ“ Explicit live-agent transfer for out-of-scope questions
* ğŸ§¾ Complete conversation transcript generation

---

## ğŸ—ï¸ Architecture Overview

User (Microphone)
â†“
Streamlit UI
â†“
Speech-to-Text (Vosk)
â†“
FAQ Retriever (Embeddings + FAISS)
â†“
Response Decision Logic
â€¢ Answer from FAQ
â€¢ Ask for clarification
â€¢ Transfer to live agent
â†“
Text-to-Speech
â†“
Audio response to user

---

## ğŸ§° Technology Stack

| Component      | Technology                  |
| -------------- | --------------------------- |
| Frontend       | Streamlit                   |
| Speech-to-Text | Vosk (open-source, offline) |
| Text-to-Speech | gTTS                        |
| PDF Parsing    | PyPDF                       |
| Retrieval      | FAISS                       |
| Embeddings     | sentence-transformers       |
| Language       | Python 3.10+                |

---

## ğŸ“‚ Project Structure

voice_faq_agent/
â”œâ”€â”€ app.py                  â€“ Streamlit UI & call flow
â”œâ”€â”€ voice_agent.py          â€“ Core agent logic
â”œâ”€â”€ pdf_loader.py           â€“ PDF parsing & chunking
â”œâ”€â”€ retriever.py            â€“ Semantic retrieval with confidence scoring
â”œâ”€â”€ stt.py                  â€“ Speech-to-Text (Vosk)
â”œâ”€â”€ tts.py                  â€“ Text-to-Speech
â”œâ”€â”€ transcript.py           â€“ Conversation transcript handling
â”œâ”€â”€ data/
â”‚   â””â”€â”€ NTTA VEHICLE BAN FAQs.FINAL.pdf
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ vosk-model-small-en-us-0.15/
â”‚   
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Create Virtual Environment

python -m venv venv
venv\Scripts\activate

---

### 2ï¸âƒ£ Install Dependencies

pip install -r requirements.txt

---

### 3ï¸âƒ£ Download Required Models

#### Vosk Speech Model

Download and extract **vosk-model-small-en-us-0.15**
[https://alphacephei.com/vosk/models](https://alphacephei.com/vosk/models)

Place it inside:
models/vosk-model-small-en-us-0.15/

---

### 4ï¸âƒ£ Place FAQ PDF

Move the provided FAQ document into the **data/** directory.

Any PDF placed inside `data/` is automatically loaded by the system.

---

### 5ï¸âƒ£ Run the Application

streamlit run app.py

Open in browser:
[http://localhost:8501](http://localhost:8501)

---

## ğŸ”„ How It Works (End-to-End Flow)

1. User speaks via microphone
2. Speech is converted to text using Vosk
3. The query is semantically matched against the FAQ PDF
4. System decision logic:

   * Strong match â†’ Answer from FAQ
   * Weak / unclear match â†’ Ask user to repeat
   * No match â†’ Transfer to live agent
5. Response is converted to speech
6. Full conversation transcript is displayed

---

## ğŸš« Out-of-Scope Handling

If a question **cannot be answered** using the FAQ document, the agent responds with:

â€œI do not have an answer to that question, let me transfer your call to the live agent.â€

This behavior strictly follows the assignment requirement and prevents hallucination.

---

## â“ Handling Unclear Speech

When speech recognition produces ambiguous or low-confidence results, the agent responds with:

â€œIâ€™m sorry, I couldnâ€™t clearly understand that. Could you please repeat or rephrase your question?â€

This ensures correctness, safety, and a natural conversational experience.

---

## âœ… Conclusion

This project demonstrates a **robust, safe, and production-aligned voice support agent** that:

* Answers strictly from provided documentation
* Never hallucinates responses
* Gracefully handles uncertainty
* Delivers a realistic, voice-first customer support experience

